{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZ4l48gv6EIi",
    "outputId": "7577d52a-2138-4ef1-8478-4d3ecdb8d264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install git+https://github.com/huggingface/transformers # need to install from github\n",
    "!pip install -q datasets loralib sentencepiece\n",
    "!pip -q install bitsandbytes accelerate xformers einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KG7V1v-36qpj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Blip2Processor, Blip2ForConditionalGeneration\n",
    "import json\n",
    "import re\n",
    "import textwrap\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LZnflIPR6uFN"
   },
   "outputs": [],
   "source": [
    "def prod_overview(url): #amazon s3 url. The location of the image\n",
    "  device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "  processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xxl\")\n",
    "  B_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\",torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", use_auth_token='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')\n",
    "  model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", device_map='auto',torch_dtype=torch.float16, use_auth_token=\"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\")\n",
    "\n",
    "  B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "  B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "  DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "  The structure of the output should look like this only, for example:\n",
    "\n",
    "  overview: 'Here's a product description for the Apple iPhone 11\n",
    "  Pro 256GB Space Grey: The Apple iPhone 11 Pro is the latest flagship device from Apple, featuring a\n",
    "  powerful A13 Bionic chip, a stunning 6.1-inch Super Retina HD display, and an impressive quad-camera\n",
    "  system. With a sleek and durable design, this phone is sure to turn heads. The A13 Bionic chip\n",
    "  provides lightning-fast performance and efficient battery life, allowing you to multitask with ease\n",
    "  and enjoy your favorite apps and games without worrying about running out of juice. The quad-camera\n",
    "  system includes a wide-angle lens, a telephoto lens, and a macro lens, giving you more creative\n",
    "  options when capturing photos and videos. The iPhone 11 Pro also features a high-quality audio\n",
    "  experience, with improved speakers and a new spatial audio feature that immerses you in your\n",
    "  favorite music, movies, and games. With Apple's advanced Face ID technology, you can unlock your\n",
    "  phone with just a glance, and the phone's long-lasting battery ensures that you can use it all day\n",
    "  without needing to recharge. In terms of design, the iPhone 11 Pro features a sleek and durable\n",
    "  stainless steel and glass construction, available in three gorgeous colors: Space Grey, Gold, and\n",
    "  Silver. The phone's IP68 rating means it can withstand being submerged in water up to 4 meters for\n",
    "  up to 30 minutes, making it perfect for those who love to take their phone with them wherever they\n",
    "  go.I hope this product description helps! Let me know if you have\n",
    "  any other questions.', 'estimated_price': '$324'\n",
    "\n",
    "  this is just an example for the products. Give me output in these way. Do not generate any additional dialogues\n",
    "\n",
    "  Your answers should not include any harmful, racist, sexist, toxic, dangerous content. Please ensure that your responses are socially unbiased, informative and positive.\n",
    "\n",
    "  Always generate a product description which is provided by the user. The description should be approximately for about 300 words. Also provide estimated price of the product\"\"\"\n",
    "\n",
    "  SYSTEM_PROMPT = B_SYS + DEFAULT_SYSTEM_PROMPT + E_SYS\n",
    "\n",
    "  def get_prompt(instruction):\n",
    "      prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "      return prompt_template\n",
    "\n",
    "  def cut_off_text(text, prompt):\n",
    "      cutoff_phrase = prompt\n",
    "      index = text.find(cutoff_phrase)\n",
    "      if index != -1:\n",
    "          return text[:index]\n",
    "      else:\n",
    "          return text\n",
    "\n",
    "  def remove_substring(string, substring):\n",
    "      return string.replace(substring, \"\")\n",
    "\n",
    "\n",
    "\n",
    "  def generate(text):\n",
    "      prompt = get_prompt(text)\n",
    "      with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "          inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "          outputs = model.generate(**inputs,\n",
    "                                  max_new_tokens=512,\n",
    "                                  eos_token_id=tokenizer.eos_token_id,\n",
    "                                  pad_token_id=tokenizer.eos_token_id,\n",
    "                                  )\n",
    "          final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "          final_outputs = cut_off_text(final_outputs, '</s>')\n",
    "          final_outputs = remove_substring(final_outputs, prompt)\n",
    "\n",
    "      return final_outputs#, outputs\n",
    "\n",
    "  def parse_text(text):\n",
    "          wrapped_text = textwrap.fill(text, width=100)\n",
    "          print(wrapped_text +'\\n\\n')\n",
    "          #return assistant_text\n",
    "\n",
    "\n",
    "  img_url = url\n",
    "  raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "  question = \"what is in the image?\"\n",
    "  inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\")\n",
    "  out = B_model.generate(**inputs)\n",
    "  prompt = processor.decode(out[0], skip_special_tokens=True)\n",
    "  generated_text = generate(prompt)\n",
    "\n",
    "  return parse_text(generated_text)\n",
    "\n",
    "\n",
    "def est_price(input_string):\n",
    "  pattern = r\"Estimated Price: \\$(\\d+)\"\n",
    "  match = re.search(pattern, input_string)\n",
    "  return match.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kn0qK90g9JWi"
   },
   "outputs": [],
   "source": [
    "x = prod_overview('https://ovantica.com/pub/media/catalog/product/cache/359e51c8e354c4e2b5af98e814f93978/i/p/iphone_11pro_max_-_iphone_11_pro_max_space_grey_-_iphone_11_pro_max_price_-_iphone_11_pro_max_review_-_buy_iphone_11_pro_max_1_1.jpeg')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
